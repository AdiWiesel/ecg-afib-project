{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2b8ae4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw dataset shape: (28085, 1800) (28085,)\n",
      "Train: (19659, 1800) (19659,)\n",
      "Validation: (4213, 1800) (4213,)\n",
      "Test: (4213, 1800) (4213,)\n",
      "Train: 19659 samples → AFib 2224 (11.31%), Normal 17435 (88.69%)\n",
      "Validation: 4213 samples → AFib 477 (11.32%), Normal 3736 (88.68%)\n",
      "Test: 4213 samples → AFib 476 (11.30%), Normal 3737 (88.70%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load dataset\n",
    "data = np.load(\"mitdb_windows_5s_binary_afib.npz\")\n",
    "X, y = data[\"X\"], data[\"y\"]\n",
    "\n",
    "print(\"Raw dataset shape:\", X.shape, y.shape)  # e.g. (936, 1800), (936,)\n",
    "\n",
    "# 2. Split into Train (70%), Temp (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 3. Split Temp into Validation (15%) and Test (15%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "# 4. Print split sizes\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation:\", X_val.shape, y_val.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# 5. Class balance check\n",
    "def summarize_split(name, y):\n",
    "    n_total = len(y)\n",
    "    n_afib  = int(y.sum())\n",
    "    n_norm  = n_total - n_afib\n",
    "    print(f\"{name}: {n_total} samples → AFib {n_afib} ({n_afib/n_total:.2%}), Normal {n_norm} ({n_norm/n_total:.2%})\")\n",
    "\n",
    "summarize_split(\"Train\", y_train)\n",
    "summarize_split(\"Validation\", y_val)\n",
    "summarize_split(\"Test\", y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f69cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw: (28085, 1800) (28085,)\n",
      "Train: 19659 | AFib 2224 (11.31%), Normal 17435 (88.69%)\n",
      "Val: 4213 | AFib 477 (11.32%), Normal 3736 (88.68%)\n",
      "Test: 4213 | AFib 476 (11.30%), Normal 3737 (88.70%)\n",
      "Extracting train features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dan23\\AppData\\Local\\Temp\\ipykernel_16076\\2328634809.py:54: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  return np.trapz(Pxx[mask], f[mask]) if np.any(mask) else 0.0\n",
      "C:\\Users\\dan23\\AppData\\Local\\Temp\\ipykernel_16076\\2328634809.py:57: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  num = np.trapz(f * Pxx, f)\n",
      "C:\\Users\\dan23\\AppData\\Local\\Temp\\ipykernel_16076\\2328634809.py:58: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  den = np.trapz(Pxx, f) + 1e-12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting val features...\n",
      "Extracting test features...\n",
      "Feature shapes: (19659, 15) (4213, 15) (4213, 15)\n",
      "Num features: 15\n",
      "Saved features → mitdb_features_v1.npz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "DATA_PATH = \"mitdb_windows_5s_binary_afib.npz\"\n",
    "FS = 360.0   # sampling rate for MIT-BIH\n",
    "SAVE_PATH = \"mitdb_features_v1.npz\"\n",
    "\n",
    "# Welch PSD params (tuned for ~5s windows)\n",
    "WELCH_NPERSEG = 512\n",
    "WELCH_NOVERLAP = 256\n",
    "\n",
    "# load data and split x/y\n",
    "d = np.load(DATA_PATH)\n",
    "X, y = d[\"X\"], d[\"y\"]\n",
    "print(\"Raw:\", X.shape, y.shape)\n",
    "\n",
    "# Stratified 70/15/15 split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, stratify=y, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "def summarize(name, yv):\n",
    "    n = len(yv)\n",
    "    af = int(yv.sum())\n",
    "    print(f\"{name}: {n} | AFib {af} ({af/n:.2%}), Normal {n-af} ({1-af/n:.2%})\")\n",
    "\n",
    "summarize(\"Train\", y_train)\n",
    "summarize(\"Val\", y_val)\n",
    "summarize(\"Test\", y_test)\n",
    "\n",
    "# feature extraction\n",
    "def zero_crossing_rate(x: np.ndarray) -> float:\n",
    "    # Count sign changes normalized by length\n",
    "    s = np.signbit(x)\n",
    "    return np.count_nonzero(s[:-1] ^ s[1:]) / len(x)\n",
    "\n",
    "def welch_psd(x: np.ndarray, fs: float):\n",
    "    f, Pxx = welch(x, fs=fs, nperseg=WELCH_NPERSEG, noverlap=WELCH_NOVERLAP)\n",
    "    return f, Pxx\n",
    "\n",
    "def bandpower(f: np.ndarray, Pxx: np.ndarray, fmin: float, fmax: float) -> float:\n",
    "    mask = (f >= fmin) & (f <= fmax)\n",
    "    # Trapezoidal integral of PSD over the band\n",
    "    return np.trapz(Pxx[mask], f[mask]) if np.any(mask) else 0.0\n",
    "\n",
    "def spectral_centroid(f: np.ndarray, Pxx: np.ndarray) -> float:\n",
    "    num = np.trapz(f * Pxx, f)\n",
    "    den = np.trapz(Pxx, f) + 1e-12\n",
    "    return num / den\n",
    "\n",
    "def dominant_frequency(f: np.ndarray, Pxx: np.ndarray) -> float:\n",
    "    return float(f[np.argmax(Pxx)]) if len(Pxx) else 0.0\n",
    "\n",
    "def extract_features_batch(Xbatch: np.ndarray, fs: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Vectorized-ish batch extractor (loops over windows, but each window’s\n",
    "    ops are NumPy/Scipy). Returns feature matrix [n_samples, n_features].\n",
    "    \"\"\"\n",
    "    feats = []\n",
    "    for x in Xbatch:\n",
    "    \n",
    "        x_mean = float(np.mean(x))\n",
    "        x_std  = float(np.std(x))\n",
    "        x_min  = float(np.min(x))\n",
    "        x_max  = float(np.max(x))\n",
    "        x_ptp  = float(np.ptp(x))\n",
    "        x_rms  = float(np.sqrt(np.mean(x**2)))\n",
    "        x_zcr  = float(zero_crossing_rate(x))\n",
    "        x_skew = float(skew(x, bias=False))\n",
    "        x_kurt = float(kurtosis(x, bias=False))\n",
    "\n",
    "        # ---- Frequency-domain (Welch PSD) ----\n",
    "        f, Pxx = welch_psd(x, fs)\n",
    "        bp_lo   = bandpower(f, Pxx, 0.5, 5.0)    # baseline/respiratory-ish\n",
    "        bp_mid  = bandpower(f, Pxx, 5.0, 15.0)   # P/QRS dominant band\n",
    "        bp_hi   = bandpower(f, Pxx, 15.0, 40.0)  # higher freq (QRS sharpness)\n",
    "        spec_c  = spectral_centroid(f, Pxx)\n",
    "        f_dom   = dominant_frequency(f, Pxx)\n",
    "        ratio_hl = bp_hi / (bp_lo + 1e-12)\n",
    "\n",
    "        feats.append([\n",
    "            x_mean, x_std, x_min, x_max, x_ptp, x_rms, x_zcr, x_skew, x_kurt,\n",
    "            bp_lo, bp_mid, bp_hi, spec_c, f_dom, ratio_hl\n",
    "        ])\n",
    "    return np.array(feats, dtype=np.float32)\n",
    "\n",
    "feature_names = [\n",
    "    \"mean\",\"std\",\"min\",\"max\",\"ptp\",\"rms\",\"zcr\",\"skew\",\"kurt\",\n",
    "    \"bp_0.5_5\",\"bp_5_15\",\"bp_15_40\",\"spec_centroid\",\"f_dominant\",\"ratio_hi_lo\"\n",
    "]\n",
    "\n",
    "print(\"Extracting train features...\")\n",
    "Xtr_feat = extract_features_batch(X_train, FS)\n",
    "print(\"Extracting val features...\")\n",
    "Xva_feat = extract_features_batch(X_val, FS)\n",
    "print(\"Extracting test features...\")\n",
    "Xte_feat = extract_features_batch(X_test, FS)\n",
    "\n",
    "print(\"Feature shapes:\", Xtr_feat.shape, Xva_feat.shape, Xte_feat.shape)\n",
    "print(\"Num features:\", len(feature_names))\n",
    "\n",
    "# avoid leak\n",
    "scaler = StandardScaler()\n",
    "Xtr_scaled = scaler.fit_transform(Xtr_feat)\n",
    "Xva_scaled = scaler.transform(Xva_feat)\n",
    "Xte_scaled = scaler.transform(Xte_feat)\n",
    "\n",
    "\n",
    "np.savez_compressed(\n",
    "    SAVE_PATH,\n",
    "    X_train_feat=Xtr_scaled,\n",
    "    X_val_feat=Xva_scaled,\n",
    "    X_test_feat=Xte_scaled,\n",
    "    y_train=y_train,\n",
    "    y_val=y_val,\n",
    "    y_test=y_test,\n",
    "    feature_names=np.array(feature_names, dtype=object),\n",
    "    scaler_mean_=scaler.mean_,\n",
    "    scaler_scale_=scaler.scale_\n",
    ")\n",
    "print(f\"Saved features → {SAVE_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
